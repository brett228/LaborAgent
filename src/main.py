# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°

# Python ê¸°ë³¸í•¨ìˆ˜
import requests
import base64
import json
import os
import glob
import numpy as np
from PIL import Image
from io import BytesIO
from datetime import datetime, timedelta
from dotenv import load_dotenv
from openai import OpenAI
from pathlib import Path

# RAG êµ¬ì„±
from chromadb import PersistentClient
from src.embeddings import get_embedding
from src.rag.load_index import load_chroma_collection, search_vector_store, search_multiple_collections

# Explicitly load .env from project root (parent of src)
env_path = Path(__file__).parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

tools = [
    {
        "type": "function",
        "function": {
            "name": "search_multiple_collections",
            "description": "Search across multiple Chroma collections and return merged top-k vector results.",
            "parameters": {
                "type": "object",
                "properties": {
                    "collection_names": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "ê²€ìƒ‰í•  chromadb collection ë¦¬ìŠ¤íŠ¸"
                    },
                    "query": {
                        "type": "string",
                        "description": "ì‚¬ìš©ì ì§ˆë¬¸"
                    },
                    "top_k": {
                        "type": "integer",
                        "description": "ê²€ìƒ‰í•  ê°œìˆ˜",
                        "default": 5
                    }
                },
                "required": ["collection_names", "query"]
            }
        }
    }
]

global session
session = []

DEFAULT_COLLECTIONS = ["iqrs"]

def get_response(query, collection_names=None, directive="", continuous=False):
    global session

    if collection_names is None:
        collection_names = DEFAULT_COLLECTIONS

    # Tools í˜¸ì¶œí•œ assistant/tool ë©”ì‹œì§€ëŠ” sessionì—ì„œ ì œê±° (ë„ˆì˜ ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
    session = [m for m in session if m["role"] not in ["tool", "assistant"]]

    if not continuous:
        session = []


    directive = """
        ë„ˆëŠ” RAG ê¸°ë°˜ ì •ë³´ ê²€ìƒ‰ ë³´ì¡° AIì•¼.
        ì‚¬ìš©ìê°€ ì§ˆë¬¸í•˜ë©´ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ê·¸ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ë§Œë“¤ì–´ì•¼ í•´.
        - ë‹µë³€ì—ëŠ” ë°˜ë“œì‹œ ê´€ë ¨ ì¶œì²˜ì™€ ë§í¬ë¥¼ í¬í•¨í•  ê²ƒ.
        - ì¶œì²˜ëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì»¬ë ‰ì…˜ ì´ë¦„ê³¼ ë¬¸ì„œ ID ë˜ëŠ” URLì„ ëª…ì‹œí•  ê²ƒ.
        - ë¬¸ì¥ì„ ë‹¨ë½ìœ¼ë¡œ êµ¬ë¶„í•˜ê³ , ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•  ê²ƒ.
    """

    if directive == "":
        session.append({"role": "user", "content": query})
    elif directive != "" and len(session) > 1:
        session.append({"role": "user", "content": query})
    else:
        session.append({"role": "system", "content": directive})
        session.append({"role": "user", "content": query})

    if len(session) > 3:
        if directive == "":
            session = session[-4:]
        else:
            session = [{"role": "system", "content": directive}] + session[-3:]

    # GPT í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=session,
        tools=tools,
        tool_choice="auto"
    )

    choice = response.choices[0]

    tool_messages = []

    # ======================================
    # ğŸ”¥ Tool Calls: search_multiple_collections
    # ======================================
    if choice.finish_reason == "tool_calls":
        for tool_call in choice.message.tool_calls:
            func_name = tool_call.function.name
            args = json.loads(tool_call.function.arguments)
            tool_call_id = tool_call.id

            if func_name == "search_multiple_collections":
                
                global chroma_client
                try:
                    chroma_client
                except NameError:
                    load_dir=Path("db/chroma_index")
                    chroma_client = PersistentClient(path=str(load_dir))

                existing_collections = [col.name for col in chroma_client.list_collections()]
                safe_collections = [name for name in args["collection_names"] if name in existing_collections]

                if not safe_collections:
                    result = {"error": "ê²€ìƒ‰ ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤."}
                else:
                    result = search_multiple_collections(
                        client=chroma_client,
                        collection_names=args["collection_names"],
                        query=args["query"],
                        get_embedding_fn=get_embedding,
                        top_k=args.get("top_k", 5),
                    )
            else:
                result = {"error": f"Unknown tool: {func_name}"}

            tool_messages.append({
                "role": "tool",
                "tool_call_id": tool_call_id,
                "name": func_name,
                "content": json.dumps(result, ensure_ascii=False)
            })

    # ================================
    # Tool ì‹¤í–‰ ê²°ê³¼ sessionì— ì¶”ê°€
    # ================================
    if choice.message.tool_calls is not None:
        session.append({"role": "assistant", "tool_calls": choice.message.tool_calls})

    for tool_msg in tool_messages:
        session.append(tool_msg)

    # ================================
    # ìµœì¢… ì‘ë‹µ ìƒì„±
    # ================================
    final_response = client.chat.completions.create(
        model="gpt-4o",
        messages=session
    )

    output_text = final_response.choices[0].message.content
    session.append({"role": "system", "content": output_text})
    return output_text


def print_session(turn=-1):
    global session
    if turn == -1:
        for query in session[:]:
            print(query["role"] + "\t" + query["content"])
            print("===================================")
    else:
        for query in session[-turn*2:]:
            if query["role"] not in ["tool"]:
                print(query["role"] + "\t" + query["content"])
                print("===================================")




def get_response(query, collection_names=None, directive="", continuous=False):
    global session

    # ê¸°ë³¸ ì»¬ë ‰ì…˜ ì§€ì •
    if collection_names is None:
        collection_names = ['iqrs']

    # Tools í˜¸ì¶œí•œ assistant/tool ë©”ì‹œì§€ëŠ” sessionì—ì„œ ì œê±°
    session = [m for m in session if m["role"] not in ["tool", "assistant"]]

    # continuous ëª¨ë“œê°€ ì•„ë‹ˆë©´ session ì´ˆê¸°í™”
    if not continuous:
        session = []

    # system ë©”ì‹œì§€ ì„¤ì •
    if not directive:
        directive = """
        ë„ˆëŠ” RAG ê¸°ë°˜ ì •ë³´ ê²€ìƒ‰ ë³´ì¡° AIì•¼.
        ì‚¬ìš©ìê°€ ì§ˆë¬¸í•˜ë©´ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ search_multiple_collections í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì•¼ í•´.
        - ê²€ìƒ‰ë˜ì§€ ì•Šì€ ì‚¬í•­ì— ëŒ€í•´ì„œëŠ” ë‹µë³€í•˜ì§€ ë§ ê²ƒ.
        - ë‹µë³€ì—ëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì¶œì²˜ì™€ ë§í¬ë¥¼ í¬í•¨í•  ê²ƒ.
        - ì»¬ë ‰ì…˜ ì´ë¦„ê³¼ ë¬¸ì„œ IDë¥¼ ëª…ì‹œí•  ê²ƒ.
        - ë¬¸ì¥ì„ ë‹¨ë½ìœ¼ë¡œ êµ¬ë¶„í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•  ê²ƒ.
        """
    session.append({"role": "system", "content": directive})

    # user ë©”ì‹œì§€ ì‚½ì…
    session.append({"role": "user", "content": query})

    # GPT í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=session,
        tools=tools,
        tool_choice="auto"
    )

    choice = response.choices[0]
    tool_messages = []

    # Tool Calls ì²˜ë¦¬
    if choice.finish_reason == "tool_calls":
        for tool_call in choice.message.tool_calls:
            func_name = tool_call.function.name
            args = json.loads(tool_call.function.arguments)
            tool_call_id = tool_call.id

            if func_name == "search_multiple_collections":
                global chroma_client
                try:
                    chroma_client
                except NameError:
                    load_dir = Path("db/chroma_index")
                    chroma_client = PersistentClient(path=str(load_dir))

                # ì¡´ì¬í•˜ëŠ” ì»¬ë ‰ì…˜ë§Œ ì‚¬ìš©
                existing_collections = [col.name for col in chroma_client.list_collections()]
                safe_collections = [name for name in args.get("collection_names", collection_names)
                                    if name in existing_collections]
                print(collection_names)

                if not existing_collections:
                    result = {"error": "ê²€ìƒ‰ ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤."}
                else:
                    result = search_multiple_collections(
                        client=chroma_client,
                        collection_names=existing_collections,
                        query=args["query"],
                        get_embedding_fn=get_embedding,
                        top_k=args.get("top_k", 5),
                    )
            else:
                result = {"error": f"Unknown tool: {func_name}"}

            tool_messages.append({
                "role": "tool",
                "tool_call_id": tool_call_id,
                "name": func_name,
                "content": json.dumps(result, ensure_ascii=False)
            })

    # Tool ì‹¤í–‰ ê²°ê³¼ sessionì— ì¶”ê°€
    if choice.message.tool_calls is not None:
        session.append({"role": "assistant", "tool_calls": choice.message.tool_calls})

    for tool_msg in tool_messages:
        session.append(tool_msg)

    # ìµœì¢… ì‘ë‹µ ìƒì„±
    final_response = client.chat.completions.create(
        model="gpt-4o",
        messages=session
    )

    output_text = final_response.choices[0].message.content
    session.append({"role": "system", "content": output_text})
    return output_text
